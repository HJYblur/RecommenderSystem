{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f583fc73-473b-423f-aee7-376077a2321a",
   "metadata": {},
   "source": [
    "# DSAIT4335 Recommender Systems\n",
    "# Assignment 2: Collaborative Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d518530c-38b5-4e5e-bbcc-1dcba666ef94",
   "metadata": {},
   "source": [
    "In this assignment, you will work to build different recommendation models under Collaborative Filtering approach, including user-based and item-based neighborhood models, and matrix factorization. Then, you will apply these recommendation models on a public dataset. The dataset is **MovieLens100K**, a movie recommendation dataset collected by GroupLens: https://grouplens.org/datasets/movielens/100k/.\n",
    "\n",
    "By the end of this assignment, you will:\n",
    "1. Understand the fundamental principles of collaborative filtering approach\n",
    "2. Implement user-based and item-based neighborhood methods\n",
    "3. Develop recommendation generation and prediction with SLIM and MF models\n",
    "4. Perform both rating prediction and top-k recommendation tasks\n",
    "5. Evaluate collaborative filtering methods to understand their strengths/limitations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5473ebe1-c51b-485a-90f5-beefb1c8e9b9",
   "metadata": {},
   "source": [
    "# Instruction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6470aee6-0d13-496f-883a-f224469b4df3",
   "metadata": {},
   "source": [
    "The MovieLens100K is already splitted into 80% training and 20% test sets. \n",
    "\n",
    "**Expected file structure** for this assignment:   \n",
    "   \n",
    "   ```\n",
    "   Assignment2/\n",
    "   ├── training.txt\n",
    "   ├── test.txt\n",
    "   └── hw2.ipynb\n",
    "   ```\n",
    "\n",
    "**Note:** Be sure to run all cells in each section sequentially, so that intermediate variables and packages are properly carried over to subsequent cells.\n",
    "\n",
    "**Submission:** Answer all the questions in this jupyter-notebook file. Submit this jupyter-notebook file (your answers included) to Brightspace. Change the name of this jupyter-notebook file to your name: firstname-lastname.ipynb."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028371e8-3f20-456f-bc81-c2b1cead2f13",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20bf874a-285c-4f84-8d63-23f16b2289bb",
   "metadata": {},
   "source": [
    "Import necessary libraries/packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb2c8cb-4471-4fb2-9da5-5204db2ff286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries imported successfully!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy.sparse import csr_matrix\n",
    "from scipy.spatial.distance import cosine, correlation\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time, math\n",
    "import warnings\n",
    "import pickle\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5fa15d0-58b0-4d34-8659-aeb64c110510",
   "metadata": {},
   "source": [
    "# 1) MovieLens100K dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64fab09-20a4-4a21-a27a-d459a2b2b2b1",
   "metadata": {},
   "source": [
    "Load the data files: training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a07dcae-eec6-4660-bc57-e2b5dcc258a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The training data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating\n",
       "0        1        1       5\n",
       "1        1        2       3\n",
       "2        1        3       4\n",
       "3        1        4       3\n",
       "4        1        5       3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the training data: (80000, 4)\n",
      "--------------------------------\n",
      "The test data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>item_id</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  item_id  rating\n",
       "0        1        6       5\n",
       "1        1       10       3\n",
       "2        1       12       5\n",
       "3        1       14       5\n",
       "4        1       17       3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the test data: (20000, 4)\n"
     ]
    }
   ],
   "source": [
    "# loading the training set and test set\n",
    "columns_name=['user_id','item_id','rating','timestamp']\n",
    "train_data = pd.read_csv('training.txt', sep='\\t', names=columns_name)\n",
    "test_data = pd.read_csv('test.txt', sep='\\t', names=columns_name)\n",
    "\n",
    "print(f'The training data:')\n",
    "display(train_data[['user_id','item_id','rating']].head())\n",
    "print(f'The shape of the training data: {train_data.shape}')\n",
    "print('--------------------------------')\n",
    "print(f'The test data:')\n",
    "display(test_data[['user_id','item_id','rating']].head())\n",
    "print(f'The shape of the test data: {test_data.shape}')\n",
    "# print(test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75b89f3c-f785-4a36-af97-5e5d778e04f0",
   "metadata": {},
   "source": [
    "# 2) User-based collaborative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdea3557-e95d-47b1-bf24-eae776f7933b",
   "metadata": {},
   "source": [
    "### Question 1: Implement a function that computes the Pearson Correlation between two users. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a692ca4-27cf-4d6b-bb92-1ce57aa551f8",
   "metadata": {},
   "source": [
    "The **Pearson correlation coefficient** between two users \\(x\\) and \\(y\\) is defined as:\n",
    "\n",
    "$$\n",
    "r_{xy} = \\frac{\\sum_{i \\in I_{xy}} (x_i - \\bar{x})(y_i - \\bar{y})}\n",
    "              {\\sqrt{\\sum_{i \\in I_{xy}} (x_i - \\bar{x})^2} \\cdot \\sqrt{\\sum_{i \\in I_{xy}} (y_i - \\bar{y})^2}}\n",
    "$$\n",
    "\n",
    "**Where:**\n",
    "\n",
    "- $I_{xy}$ = set of items rated by both users  \n",
    "- $x_i$, $y_i$ = ratings of users \\(x\\) and \\(y\\) on item \\(i\\)  \n",
    "- $\\bar{x}$, $\\bar{y}$ = mean ratings of users \\(x\\) and \\(y\\) on the common items  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "88579c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_ratings(user_id: int):\n",
    "    return train_data[train_data['user_id'] == user_id].set_index('item_id')['rating']\n",
    "\n",
    "def extract_ratings_item(user_id: int, item_id: int):\n",
    "    result = train_data[(train_data['user_id'] == user_id) & (train_data['item_id'] == item_id)]['rating']\n",
    "    if len(result) > 0:\n",
    "        return result.iloc[0]\n",
    "    else:\n",
    "        return np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f17b4c4-3eb0-44fe-998e-dec73fba9066",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson Correlation between users 1 and 2 is 0.2697\n"
     ]
    }
   ],
   "source": [
    "def pearson_correlation(user1_ratings: pd.Series, user2_ratings: pd.Series) -> float:\n",
    "    \"\"\"\n",
    "    Compute Pearson correlation coefficient between two users' rating vectors.\n",
    "    \n",
    "    user1_ratings, user2_ratings: Pandas Series indexed by item IDs. They may contain NaN for unrated items.\n",
    "    Returns: float (correlation between -1 and 1). Returns 0 if not enough data.\n",
    "    \"\"\"\n",
    "    result = 0.0\n",
    "    \n",
    "    ############# Your code here ############\n",
    "    '''\n",
    "        Data format:\n",
    "        ratings = [ratings1, ratings2, ...] -> idx = item_id\n",
    "    '''\n",
    "    # Find common items rated by both users\n",
    "    common_item_indexs = user1_ratings.index.intersection(user2_ratings.index)\n",
    "    \n",
    "    # Remove items with NaN values\n",
    "    valid_indices = []\n",
    "    for idx in common_item_indexs:\n",
    "        if not (pd.isna(user1_ratings[idx]) or pd.isna(user2_ratings[idx])):\n",
    "            # print(f\"Item {idx} rated by both users: User1 rating = {user1_ratings[idx]}, User2 rating = {user2_ratings[idx]}\")\n",
    "            valid_indices.append(idx)\n",
    "    \n",
    "    common_item_indexs = pd.Index(valid_indices)\n",
    "            \n",
    "    # Check if they have common ratings\n",
    "    # print(f\"Common items rated by both users: {common_item_indexs.tolist()}\")  # Comment out for matrix computation\n",
    "    if len(common_item_indexs) <= 1:  # Need at least 2 items for correlation\n",
    "        return 0.0\n",
    "            \n",
    "    user1_pure = user1_ratings[common_item_indexs]\n",
    "    user2_pure = user2_ratings[common_item_indexs]\n",
    "\n",
    "    user1_mean = np.mean(user1_pure)\n",
    "    user2_mean = np.mean(user2_pure)\n",
    "    \n",
    "    user1_diff = (user1_pure - user1_mean)\n",
    "    user2_diff = (user2_pure - user2_mean)\n",
    "\n",
    "    nominator = np.sum(user1_diff * user2_diff)\n",
    "    denominator_sqrt = np.sqrt(np.sum(user1_diff * user1_diff) * np.sum(user2_diff * user2_diff))\n",
    "    \n",
    "    # Check for zero denominator (constant ratings)\n",
    "    if denominator_sqrt == 0:\n",
    "        return 0.0\n",
    "    #########################################\n",
    "    \n",
    "    return nominator / denominator_sqrt\n",
    "\n",
    "user1, user2 = 1, 2\n",
    "# user1_ratings = train_data[train_data['user_id'] == user1].set_index('item_id')['rating']\n",
    "# user2_ratings = train_data[train_data['user_id'] == user2].set_index('item_id')['rating']\n",
    "\n",
    "user1_ratings = extract_ratings(user1)\n",
    "user2_ratings = extract_ratings(user2)\n",
    "print(f\"Pearson Correlation between users {user1} and {user2} is {pearson_correlation(user1_ratings, user2_ratings):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93a6fe9b-fd75-4e43-84b3-b5cabeace2b5",
   "metadata": {},
   "source": [
    "### Question 2: What is the similarity value between users <8,9>. Discuss your observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4d01e8c7-a6c7-454f-bb53-e66f7d959c0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson Correlation between users 9 and 8 is 0.0000\n"
     ]
    }
   ],
   "source": [
    "user1, user2 = 9, 8\n",
    "sim = 0.0\n",
    "\n",
    "############# Your code here ############\n",
    "user1_ratings = extract_ratings(user1)\n",
    "user2_ratings = extract_ratings(user2)\n",
    "\n",
    "sim = pearson_correlation(user1_ratings, user2_ratings)\n",
    "#########################################\n",
    "\n",
    "\n",
    "print(f\"Pearson Correlation between users {user1} and {user2} is {sim:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affa90e1-1c94-4a82-a03d-74b3a433ab1b",
   "metadata": {},
   "source": [
    "### Question 3: What is the similarity value between users <2,3>? Discuss your observation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "400b1f63-a5d2-4711-8187-b28d0988954a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson Correlation between users 2 and 3 is 0.0000\n"
     ]
    }
   ],
   "source": [
    "user1, user2 = 2, 3\n",
    "sim = 0.0\n",
    "\n",
    "############# Your code here ############\n",
    "user1_ratings = extract_ratings(user1)\n",
    "user2_ratings = extract_ratings(user2)\n",
    "\n",
    "sim = pearson_correlation(user1_ratings, user2_ratings)\n",
    "\n",
    "#########################################\n",
    "\n",
    "print(f\"Pearson Correlation between users {user1} and {user2} is {sim:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f7ff4a",
   "metadata": {},
   "source": [
    "### Note 1-3\n",
    "\n",
    "For Question 2, there is no common ratings, so the correlation should directly return to 0.0;\n",
    "\n",
    "For Question 3, user 2 has constant ratings, which results in the denominator being 0, thus will cause NaN error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18187672-35e4-44dc-8c4e-01aa6b1daf81",
   "metadata": {},
   "source": [
    "### Question 4: Create the user-user similarity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d0965d17-a82c-4f43-9478-d032a0a0c340",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded user_similarity_matrix from file.\n"
     ]
    }
   ],
   "source": [
    "def compute_user_similarity_matrix(train_data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute user-user similarity matrix using Pearson correlation.\n",
    "    \n",
    "    Parameters:\n",
    "    - ratings: pd.DataFrame with columns ['user_id', 'item_id', 'rating']\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: user-user similarity matrix (rows & cols = user_ids)\n",
    "    \"\"\"\n",
    "    users = train_data['user_id'].unique()\n",
    "    user_similarity_matrix = pd.DataFrame(np.zeros((len(users), len(users))), index=users, columns=users)\n",
    "    \n",
    "    ############# Your code here ############\n",
    "    user_ratings = {user: train_data[train_data['user_id'] == user].set_index('item_id')['rating'] for user in users}\n",
    "    \n",
    "    for i, user1 in enumerate(users):\n",
    "        for j, user2 in enumerate(users):\n",
    "            if i <= j:  # Only compute upper triangle + diagonal to avoid duplicates\n",
    "                if i == j:\n",
    "                    # Self-similarity is always 1\n",
    "                    user_similarity_matrix.loc[user1, user2] = 1.0\n",
    "                else:\n",
    "                    # Compute similarity between different users\n",
    "                    val = pearson_correlation(user_ratings[user1], user_ratings[user2])\n",
    "                    user_similarity_matrix.loc[user1, user2] = val\n",
    "                    user_similarity_matrix.loc[user2, user1] = val\n",
    "    #########################################\n",
    "    \n",
    "    return user_similarity_matrix\n",
    "\n",
    "\n",
    "sim_matrix_path = \"user_similarity_matrix.pkl\"\n",
    "if os.path.exists(sim_matrix_path):\n",
    "    with open(sim_matrix_path, \"rb\") as f:\n",
    "        user_similarity_matrix = pickle.load(f)\n",
    "    print(\"Loaded user_similarity_matrix from file.\")\n",
    "else:\n",
    "    start_time = time.time()\n",
    "    print(f'Similarity matrix creation started! This may take around 5-10 minutes...')\n",
    "    user_similarity_matrix = compute_user_similarity_matrix(train_data)\n",
    "    end_time = time.time()\n",
    "    print(f'Running time: {end_time - start_time:.4f} seconds')\n",
    "    \n",
    "    with open(sim_matrix_path, \"wb\") as f:\n",
    "        pickle.dump(user_similarity_matrix, f)\n",
    "    print(\"Computed and saved user_similarity_matrix.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65290a4d-c961-4cf4-b83c-dbf2fb28f9d6",
   "metadata": {},
   "source": [
    "### Question 5: Implement a function that returns k most similar users along with the similarity values to a target user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9d29e3-8535-491e-a797-10ef60f7c876",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neighbors of user 1 are:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(1, 1.0),\n",
       " (238, 1.0),\n",
       " (616, 1.0),\n",
       " (29, 1.0),\n",
       " (229, 1.0),\n",
       " (898, 1.0),\n",
       " (656, 1.0),\n",
       " (724, 1.0),\n",
       " (732, 1.0),\n",
       " (289, 1.0)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_k_user_neighbors(user_similarity_matrix: pd.DataFrame, target_user, k=5):\n",
    "    \"\"\"\n",
    "    Retrieve top-k most similar users to the target user.\n",
    "\n",
    "    Parameters:\n",
    "    - user_similarity_matrix: pd.DataFrame, user-user similarity values (indexed by user IDs)\n",
    "    - target_user: user ID for whom we want neighbors\n",
    "    - k: number of neighbors to retrieve\n",
    "\n",
    "    Returns:\n",
    "    - List of tuples: [(neighbor_user_id, similarity), ...] sorted by similarity descending\n",
    "    \"\"\"\n",
    "    top_k_neighbors = []\n",
    "    \n",
    "    ############# Your code here ############\n",
    "    target_row = user_similarity_matrix.loc[target_user]\n",
    "    # print(target_row)\n",
    "    target_row.drop(target_user) # Remove itself\n",
    "    sorted_target_row = target_row.sort_values(ascending = False)\n",
    "    k = min(k, len(sorted_target_row))\n",
    "    for i in range(k):\n",
    "        top_k_neighbors.append((sorted_target_row.index[i], sorted_target_row.iloc[i]))\n",
    "    \n",
    "    #########################################\n",
    "    \n",
    "    return top_k_neighbors\n",
    "\n",
    "target_user, k = 1, 10\n",
    "print(f\"Neighbors of user {target_user} are:\")\n",
    "get_k_user_neighbors(user_similarity_matrix, target_user, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f55e8623-ef96-4c86-8c63-ababc1bb0471",
   "metadata": {},
   "source": [
    "### Question 6: Implement a function that predicts the rating for a target user might give to a target item using user-user similarity matrix and the following equation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634ed3cf-ec4a-4fbb-950f-7efefb9db329",
   "metadata": {},
   "source": [
    "The **predicted rating** for a target user \\(u\\) on item \\(i\\) using mean-centered user-based collaborative filtering is:\n",
    "\n",
    "$$\n",
    "\\hat{r}_{u,i} = \\bar{r}_u + \\frac{\\sum_{v \\in N(u)} s(u,v) \\cdot (r_{v,i} - \\bar{r}_v)}\n",
    "                             {\\sum_{v \\in N(u)} |s(u,v)|}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- $\\hat{r}_{u,i}$ = predicted rating for user \\(u\\) on item \\(i\\)  \n",
    "- $\\bar{r}_u$ = mean rating of the target user \\(u\\)  \n",
    "- $N(u)$ = set of top-\\(k\\) neighbors of user \\(u\\) who have rated item \\(i\\)  \n",
    "- $s(u,v)$ = similarity between users \\(u\\) and \\(v\\)  \n",
    "- $r_{v,i}$ = rating of neighbor \\(v\\) on item \\(i\\)  \n",
    "- $\\bar{r}_v$ = mean rating of neighbor \\(v\\)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b17d50-901b-4f0f-ac19-55732c8f2cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The actual rating for user 1 and item 17 is 3. The predicted rating by user-based CF for user 1 and item 17 is 2.4157\n"
     ]
    }
   ],
   "source": [
    "def predict_rating_user_based(train_data: pd.DataFrame, user_similarity_matrix: pd.DataFrame, target_user, target_item, k=5):\n",
    "    \"\"\"\n",
    "    Predict rating for target_user and target_item using mean-centered user-based CF.\n",
    "\n",
    "    Parameters:\n",
    "    - ratings: pd.DataFrame with columns ['user_id', 'item_id', 'rating']\n",
    "    - user_similarity_matrix: pd.DataFrame of user-user similarities\n",
    "    - target_user: user ID\n",
    "    - target_item: item ID\n",
    "    - k: number of neighbors to consider\n",
    "\n",
    "    Returns:\n",
    "    - float: predicted rating, or np.nan if not possible\n",
    "    \"\"\"\n",
    "    result = 0.0\n",
    "    \n",
    "    ############# Your code here ############\n",
    "    \n",
    "    target_user_ratings = train_data[train_data['user_id'] == target_user]['rating']\n",
    "    r_user_mean = np.mean(target_user_ratings)\n",
    "    \n",
    "    \n",
    "    neighbors = get_k_user_neighbors(user_similarity_matrix, target_user, k)\n",
    "    valid_neighbors = []\n",
    "    for neighbor_id, similarity in neighbors:\n",
    "        neighbor_rating = extract_ratings_item(neighbor_id, target_item)\n",
    "        if not pd.isna(neighbor_rating):\n",
    "            valid_neighbors.append((neighbor_id, similarity))\n",
    "    \n",
    "    if len(valid_neighbors) == 0:\n",
    "        return np.nan\n",
    "    \n",
    "    \n",
    "    nominator = 0.0\n",
    "    denominator = 0.0\n",
    "    for neighbor_id, similarity in valid_neighbors:\n",
    "        r_vi = extract_ratings_item(neighbor_id, target_item)\n",
    "        \n",
    "        # Get neighbor's mean rating\n",
    "        neighbor_ratings = train_data[train_data['user_id'] == neighbor_id]['rating']\n",
    "        r_v_mean = np.mean(neighbor_ratings)\n",
    "        \n",
    "        nominator += similarity * (r_v_mean - r_vi)\n",
    "        denominator += abs(similarity)\n",
    "        \n",
    "    result = r_user_mean + nominator / denominator if denominator != 0.0 else np.nan\n",
    "    #########################################\n",
    "\n",
    "    return result\n",
    "\n",
    "target_user, target_item, k = 1, 17, 50\n",
    "print(f\"The actual rating for user {target_user} and item {target_item} is 3. The predicted rating by user-based CF for user {target_user} and item {target_item} is {predict_rating_user_based(train_data, user_similarity_matrix, target_user, target_item, k):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3ade2d4-c1b8-495f-b593-945c4c4984be",
   "metadata": {},
   "source": [
    "### Question 7: Implement a function that generates top-10 recommendation list for a target user using user-based CF method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d95314d7-fd84-4c12-a63b-61387265af44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-10 recommendations for user 1:\n",
      "Item 8: 6.3630\n",
      "Item 29: 6.3630\n",
      "Item 35: 6.3630\n",
      "Item 110: 6.3630\n",
      "Item 131: 6.3630\n",
      "Item 138: 6.3630\n",
      "Item 231: 6.3630\n",
      "Item 247: 6.3630\n",
      "Item 263: 6.3630\n",
      "Item 353: 6.2815\n",
      "Running time: 11.2233 seconds\n"
     ]
    }
   ],
   "source": [
    "def recommend_topk_user_based(train_data, user_similarity_matrix, target_user, k=5):\n",
    "    \"\"\"\n",
    "    Generate Top-K recommendations for a target user using User-based CF.\n",
    "    \n",
    "    Args:\n",
    "        train_data (pd.DataFrame): ratings data with columns [user_id, item_id, rating]\n",
    "        user_similarity_matrix (pd.DataFrame): precomputed user-user similarity matrix\n",
    "        target_user (int): user_id of the target user\n",
    "        k (int): number of most similar neighbors to consider\n",
    "    \n",
    "    Returns:\n",
    "        list of (item_id, predicted_score) sorted by score desc\n",
    "    \"\"\"\n",
    "    result = []\n",
    "    \n",
    "    ############# Your code here ############\n",
    "    items = train_data['item_id'].unique()\n",
    "    pred_ratings = []\n",
    "    for item in items:\n",
    "        pred_rating = predict_rating_user_based(train_data, user_similarity_matrix, target_user, item, k)\n",
    "        if not pd.isna(pred_rating):\n",
    "            pred_ratings.append((item, pred_rating))\n",
    "            \n",
    "    pred_ratings.sort(key=lambda x: x[1], reverse=True)\n",
    "    result = pred_ratings[:10] \n",
    "    #########################################\n",
    "    \n",
    "    return result\n",
    "\n",
    "start_time = time.time()\n",
    "target_user, k = 1, 30\n",
    "recommendations = recommend_topk_user_based(train_data, user_similarity_matrix, target_user, k)\n",
    "print(f\"Top-10 recommendations for user {target_user}:\")\n",
    "for item, score in recommendations:\n",
    "    print(f\"Item {item}: {score:.4f}\")\n",
    "end_time = time.time()\n",
    "print(f'Running time: {end_time - start_time:.4f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "817a8b1d-808c-4eb5-9c14-35c1dc446c0e",
   "metadata": {},
   "source": [
    "# 3) Item-based collaborative filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5004d046-a823-49db-bed8-cf32fc404628",
   "metadata": {},
   "source": [
    "### Question 8: Implement a function that computes the Cosine similarity between two items. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4431d9d-61c8-4c51-b316-e4c8d54babf6",
   "metadata": {},
   "source": [
    "The **cosine similarity** between two items \\(i\\) and \\(j\\) is defined as:\n",
    "\n",
    "$$\n",
    "\\text{sim}(i,j) = \\frac{\\sum_{u \\in U_{ij}} r_{u,i} \\cdot r_{u,j}}\n",
    "                      {\\sqrt{\\sum_{u \\in U_{ij}} r_{u,i}^2} \\cdot \\sqrt{\\sum_{u \\in U_{ij}} r_{u,j}^2}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- \\(r_{u,i}\\) = rating of user \\(u\\) on item \\(i\\)  \n",
    "- \\(r_{u,j}\\) = rating of user \\(u\\) on item \\(j\\)  \n",
    "- \\(U_{ij}\\) = set of users who have rated both items \\(i\\) and \\(j\\)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3e9d3d-2347-4f87-80a7-d6129a7fa7a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(item1_ratings: pd.Series, item2_ratings: pd.Series) -> float:\n",
    "    \"\"\"\n",
    "    Compute cosine similarity between two items' rating vectors.\n",
    "    Only common users are considered.\n",
    "    \n",
    "    Parameters:\n",
    "    - item1_ratings, item2_ratings: pd.Series indexed by user_id\n",
    "    \n",
    "    Returns:\n",
    "    - float: cosine similarity between -1 and 1\n",
    "    \"\"\"\n",
    "    result = 0.0\n",
    "    \n",
    "    ############# Your code here ############\n",
    "    \n",
    "    #########################################\n",
    "\n",
    "    return result\n",
    "\n",
    "item1, item2 = 1, 2\n",
    "item1_ratings = train_data[train_data['item_id'] == item1].set_index('user_id')['rating']\n",
    "item2_ratings = train_data[train_data['item_id'] == item2].set_index('user_id')['rating']\n",
    "print(f\"Cosine similarity between items {item1} and {item2} is {cosine_similarity(item1_ratings, item2_ratings):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fb85cd0-d13f-4e40-a685-4e591b307190",
   "metadata": {},
   "source": [
    "### Question 9: Create the item-item similarity matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ff4eead-d1c5-4eab-bca3-a909ddccaf34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_item_similarity_matrix(train_data: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute item-item similarity matrix using cosine similarity.\n",
    "    \n",
    "    Parameters:\n",
    "    - ratings: pd.DataFrame with columns ['user_id', 'item_id', 'rating']\n",
    "    \n",
    "    Returns:\n",
    "    - pd.DataFrame: item-item similarity matrix (rows & cols = item_ids)\n",
    "    \"\"\"\n",
    "    items = train_data['item_id'].unique()\n",
    "    item_similarity_matrix = pd.DataFrame(np.zeros((len(items), len(items))), index=items, columns=items)\n",
    "    \n",
    "    ############# Your code here ############\n",
    "    \n",
    "    #########################################\n",
    "    \n",
    "    return item_similarity_matrix\n",
    "\n",
    "start_time = time.time()\n",
    "item_similarity_matrix = compute_item_similarity_matrix(train_data)  \n",
    "end_time = time.time()\n",
    "print(f'Running time: {end_time - start_time:.4f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f8578e-a1c3-48df-80e4-ee54a8a1c846",
   "metadata": {},
   "source": [
    "### Question 10: Implement a function that returns k most similar item along with the similarity values to a target item."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7a7bd5-52c7-4f97-982e-226c348485d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_k_item_neighbors(item_similarity_matrix: pd.DataFrame, target_item, k=5):\n",
    "    \"\"\"\n",
    "    Retrieve top-k most similar items to the target item.\n",
    "    \n",
    "    Parameters:\n",
    "    - item_similarity_matrix: pd.DataFrame, item-item similarity\n",
    "    - target_item: item ID\n",
    "    - k: number of neighbors\n",
    "    \n",
    "    Returns:\n",
    "    - List of tuples: [(neighbor_item_id, similarity), ...]\n",
    "    \"\"\"\n",
    "    top_k_neighbors = []\n",
    "\n",
    "    ############# Your code here ############\n",
    "    \n",
    "    #########################################\n",
    "    \n",
    "    return top_k_neighbors\n",
    "\n",
    "target_item, k = 1, 10\n",
    "print(f\"Neighbors of item {target_item} are:\")\n",
    "get_k_item_neighbors(item_similarity_matrix, target_item, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6ab134-7998-40b5-a1c4-f4689b77f0c2",
   "metadata": {},
   "source": [
    "### Question 11: Implement a function that predicts the rating for a target user might give to a target item using item-item similarity matrix and the following equation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce27fdf-ee88-4031-8f1a-7d9f3c567eb1",
   "metadata": {},
   "source": [
    "The **predicted rating** for a target user \\(u\\) on a target item \\(i\\) using item-based collaborative filtering is:\n",
    "\n",
    "$$\n",
    "\\hat{r}_{u,i} = \\frac{\\sum_{j \\in N(i)} s(i,j) \\cdot r_{u,j}}{\\sum_{j \\in N(i)} |s(i,j)|}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "\n",
    "- \\(\\hat{r}_{u,i}\\) = predicted rating of user \\(u\\) on item \\(i\\)  \n",
    "- \\(N(i)\\) = set of top-\\(k\\) most similar items to item \\(i\\) that user \\(u\\) has rated  \n",
    "- \\(s(i,j)\\) = similarity between item \\(i\\) and item \\(j\\)  \n",
    "- \\(r_{u,j}\\) = rating of user \\(u\\) on item \\(j\\)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94860413-1ead-435f-8f44-6f6cf36f55d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_rating_item_based(train_data: pd.DataFrame, item_similarity_matrix: pd.DataFrame, target_user, target_item, k=5):\n",
    "    \"\"\"\n",
    "    Predict rating using item-based CF (non-mean centric).\n",
    "    \n",
    "    Parameters:\n",
    "    - ratings: pd.DataFrame ['user_id', 'item_id', 'rating']\n",
    "    - item_similarity_matrix: item-item similarity DataFrame\n",
    "    - target_user: user ID\n",
    "    - target_item: item ID\n",
    "    - k: number of neighbors to use\n",
    "    \n",
    "    Returns:\n",
    "    - float: predicted rating, or np.nan if not enough data\n",
    "    \"\"\"\n",
    "    result = 0.0\n",
    "\n",
    "    ############# Your code here ############\n",
    "    \n",
    "    #########################################\n",
    "    \n",
    "    return result\n",
    "\n",
    "target_user, target_item, k = 1, 17, 50\n",
    "print(f\"The actual rating for user {target_user} and item {target_item} is 3. The predicted rating by item-based CF for user {target_user} and item {target_item} is {predict_rating_item_based(train_data, item_similarity_matrix, target_user, target_item, k):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fb4ef15-5780-4654-b5f3-3add75a26e62",
   "metadata": {},
   "source": [
    "### Question 12: Implement a function that generates top-10 recommendation list for a target user using item-based CF method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d71aecc-6d94-4929-a146-3e448fb28d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_topk_item_based(train_data, item_similarity_matrix, target_user, k=5):\n",
    "    \"\"\"\n",
    "    Generate Top-K recommendations for a target user using Item-based CF.\n",
    "    \n",
    "    Args:\n",
    "        train_data (pd.DataFrame): ratings data with columns [user_id, item_id, rating]\n",
    "        item_similarity_matrix (pd.DataFrame): precomputed item-item similarity matrix\n",
    "        target_user (int): user_id of the target user\n",
    "        k (int): number of items to recommend\n",
    "    \n",
    "    Returns:\n",
    "        list of (item_id, predicted_score) sorted by score desc\n",
    "    \"\"\"\n",
    "    result = []\n",
    "\n",
    "    ############# Your code here ############\n",
    "    \n",
    "    #########################################\n",
    "    \n",
    "    return result\n",
    "\n",
    "target_user, k = 1, 50\n",
    "recommendations = recommend_topk_item_based(train_data, item_similarity_matrix, target_user, k)\n",
    "print(f\"Top-10 recommendations for user {target_user}:\")\n",
    "for item, score in recommendations:\n",
    "    print(f\"Item {item}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9645ad32-55b7-497d-b3f9-9b16fc01e483",
   "metadata": {},
   "source": [
    "# 3) Matrix Factorization (MF)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4978d85d-260e-492b-8b7d-3e8fecd53c8e",
   "metadata": {},
   "source": [
    "For details about matrix factorization algorithm see the lecture in week 3.\n",
    "\n",
    "Matrix factorization algorithm is implemented in the next cell. Run the following cell and then use it to build MF model for running experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "480b9a63-2899-4e88-bb5f-0a96541180a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MatrixFactorizationSGD:\n",
    "    \"\"\"\n",
    "    Matrix Factorization for rating prediction using Stochastic Gradient Descent (SGD).\n",
    "    \n",
    "    Rating matrix R ≈ P × Q^T + biases\n",
    "    \"\"\"\n",
    "    def __init__(self, n_factors=20, learning_rate=0.01, regularization=0.02, n_epochs=20, use_bias=True):\n",
    "        self.n_factors = n_factors\n",
    "        self.learning_rate = learning_rate\n",
    "        self.regularization = regularization\n",
    "        self.n_epochs = n_epochs\n",
    "        self.use_bias = use_bias\n",
    "\n",
    "        # Model parameters\n",
    "        self.P = None  # User latent factors\n",
    "        self.Q = None  # Item latent factors\n",
    "        self.user_bias = None\n",
    "        self.item_bias = None\n",
    "        self.global_mean = None\n",
    "\n",
    "    def fit(self, ratings, verbose=True):\n",
    "        \"\"\"\n",
    "        Train the model.\n",
    "        \n",
    "        Args:\n",
    "            ratings (pd.DataFrame): dataframe with [user_id, item_id, rating]\n",
    "        \"\"\"\n",
    "        # Map IDs to indices\n",
    "        self.user_mapping = {u: i for i, u in enumerate(ratings['user_id'].unique())}\n",
    "        self.item_mapping = {i: j for j, i in enumerate(ratings['item_id'].unique())}\n",
    "        self.user_inv = {i: u for u, i in self.user_mapping.items()}\n",
    "        self.item_inv = {j: i for i, j in self.item_mapping.items()}\n",
    "\n",
    "        n_users = len(self.user_mapping)\n",
    "        n_items = len(self.item_mapping)\n",
    "\n",
    "        # Initialize factors\n",
    "        self.P = np.random.normal(0, 0.1, (n_users, self.n_factors))\n",
    "        self.Q = np.random.normal(0, 0.1, (n_items, self.n_factors))\n",
    "\n",
    "        if self.use_bias:\n",
    "            self.user_bias = np.zeros(n_users)\n",
    "            self.item_bias = np.zeros(n_items)\n",
    "            self.global_mean = ratings['rating'].mean()\n",
    "\n",
    "        # Convert to (user_idx, item_idx, rating) triples\n",
    "        training_data = [(self.user_mapping[u], self.item_mapping[i], r)\n",
    "                         for u, i, r in zip(ratings['user_id'], ratings['item_id'], ratings['rating'])]\n",
    "\n",
    "        # SGD loop\n",
    "        for epoch in range(self.n_epochs):\n",
    "            np.random.shuffle(training_data)\n",
    "            total_error = 0\n",
    "\n",
    "            for u, i, r in training_data:\n",
    "                pred = np.dot(self.P[u], self.Q[i])\n",
    "                if self.use_bias:\n",
    "                    pred += self.global_mean + self.user_bias[u] + self.item_bias[i]\n",
    "\n",
    "                err = r - pred\n",
    "                total_error += err ** 2\n",
    "\n",
    "                # Updates\n",
    "                P_u = self.P[u]\n",
    "                Q_i = self.Q[i]\n",
    "\n",
    "                self.P[u] += self.learning_rate * (err * Q_i - self.regularization * P_u)\n",
    "                self.Q[i] += self.learning_rate * (err * P_u - self.regularization * Q_i)\n",
    "\n",
    "                if self.use_bias:\n",
    "                    self.user_bias[u] += self.learning_rate * (err - self.regularization * self.user_bias[u])\n",
    "                    self.item_bias[i] += self.learning_rate * (err - self.regularization * self.item_bias[i])\n",
    "\n",
    "            rmse = np.sqrt(total_error / len(training_data))\n",
    "            if verbose:\n",
    "                print(f\"Epoch {epoch+1}/{self.n_epochs} - RMSE: {rmse:.4f}\")\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict_single(self, user_id, item_id):\n",
    "        \"\"\"Predict rating for a single (user, item) pair\"\"\"\n",
    "        if user_id not in self.user_mapping or item_id not in self.item_mapping:\n",
    "            return np.nan\n",
    "\n",
    "        u = self.user_mapping[user_id]\n",
    "        i = self.item_mapping[item_id]\n",
    "\n",
    "        pred = np.dot(self.P[u], self.Q[i])\n",
    "        if self.use_bias:\n",
    "            pred += self.global_mean + self.user_bias[u] + self.item_bias[i]\n",
    "        return pred\n",
    "\n",
    "    def predict(self, test_data):\n",
    "        \"\"\"Predict ratings for a test dataframe with [user_id, item_id]\"\"\"\n",
    "        preds = []\n",
    "        for u, i in zip(test_data['user_id'], test_data['item_id']):\n",
    "            preds.append(self.predict_single(u, i))\n",
    "        return np.array(preds)\n",
    "\n",
    "    def recommend_topk(self, user_id, train_data, n=10, exclude_seen=True):\n",
    "        \"\"\"\n",
    "        Generate Top-K recommendations for a given user.\n",
    "\n",
    "        Args:\n",
    "            user_id (int): target user ID (original ID, not index).\n",
    "            train_data (pd.DataFrame): training ratings [user_id, item_id, rating],\n",
    "                                       used to exclude already-seen items.\n",
    "            k (int): number of recommendations.\n",
    "            exclude_seen (bool): whether to exclude items the user already rated.\n",
    "\n",
    "        Returns:\n",
    "            list of (item_id, predicted_score) sorted by score desc.\n",
    "        \"\"\"\n",
    "        if user_id not in self.user_mapping:\n",
    "            return []\n",
    "\n",
    "        u = self.user_mapping[user_id]\n",
    "\n",
    "        # Predict scores for all items\n",
    "        scores = np.dot(self.P[u], self.Q.T)\n",
    "        if self.use_bias:\n",
    "            scores += self.global_mean + self.user_bias[u] + self.item_bias\n",
    "\n",
    "        # Exclude seen items\n",
    "        if exclude_seen:\n",
    "            seen_items = train_data[train_data['user_id'] == user_id]['item_id'].values\n",
    "            seen_idx = [self.item_mapping[i] for i in seen_items if i in self.item_mapping]\n",
    "            scores[seen_idx] = -np.inf\n",
    "\n",
    "        # Get top-K items\n",
    "        top_idx = np.argsort(scores)[::-1][:n]\n",
    "        top_items = [self.item_inv[i] for i in top_idx]\n",
    "        top_scores = scores[top_idx]\n",
    "\n",
    "        return list(zip(top_items, top_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e6ec43-8c71-4c30-9599-b52a3fdabcfe",
   "metadata": {},
   "source": [
    "#### Sample usage for rating prediction task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "4397fe25-e8be-4ad6-966a-398f5588f12c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - RMSE: 1.0961\n",
      "Epoch 2/10 - RMSE: 1.0569\n",
      "Epoch 3/10 - RMSE: 1.0308\n",
      "Epoch 4/10 - RMSE: 1.0121\n",
      "Epoch 5/10 - RMSE: 0.9980\n",
      "Epoch 6/10 - RMSE: 0.9869\n",
      "Epoch 7/10 - RMSE: 0.9779\n",
      "Epoch 8/10 - RMSE: 0.9704\n",
      "Epoch 9/10 - RMSE: 0.9640\n",
      "Epoch 10/10 - RMSE: 0.9585\n",
      "The actual rating for user 1 and item 17 is 3. The predicted rating by MF for user 1 and item 17 is 3.2838\n"
     ]
    }
   ],
   "source": [
    "# Train model \n",
    "# Parameters: n_factors refers to embedding size, n_epochs refers to number of epochs, learning_rate refers to learning rate, and regularization refers to lambda hyperparameter controlling the effect of regularization terms\n",
    "mf = MatrixFactorizationSGD(n_factors=50, n_epochs=10, learning_rate=0.001, regularization=0.001)\n",
    "mf.fit(train_data, verbose=True)\n",
    "\n",
    "# predict the rating for a target user and a target item\n",
    "target_user = 1\n",
    "target_item = 17\n",
    "actual_rating = 3\n",
    "pred_rating = mf.predict_single(target_user, target_item)\n",
    "print(f\"The actual rating for user {target_user} and item {target_item} is 3. The predicted rating by MF for user {target_user} and item {target_item} is {pred_rating:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "376ae6f1-3ada-4693-b6c2-0a0f449e0883",
   "metadata": {},
   "source": [
    "#### Sample usage for ranking task:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "1e3faae4-684a-4389-b14a-8d9b157c3b85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - RMSE: 1.0943\n",
      "Epoch 2/10 - RMSE: 1.0558\n",
      "Epoch 3/10 - RMSE: 1.0305\n",
      "Epoch 4/10 - RMSE: 1.0125\n",
      "Epoch 5/10 - RMSE: 0.9991\n",
      "Epoch 6/10 - RMSE: 0.9888\n",
      "Epoch 7/10 - RMSE: 0.9805\n",
      "Epoch 8/10 - RMSE: 0.9737\n",
      "Epoch 9/10 - RMSE: 0.9680\n",
      "Epoch 10/10 - RMSE: 0.9632\n",
      "Top-5 Recommendations for user 1:\n",
      "Item 318: 4.4215\n",
      "Item 64: 4.3744\n",
      "Item 483: 4.3730\n",
      "Item 12: 4.3684\n",
      "Item 98: 4.3340\n",
      "Item 174: 4.2826\n",
      "Item 313: 4.2805\n",
      "Item 357: 4.2692\n",
      "Item 603: 4.2425\n",
      "Item 427: 4.2256\n"
     ]
    }
   ],
   "source": [
    "# Train model \n",
    "# Parameters: n_factors refers to embedding size, n_epochs refers to number of epochs, learning_rate refers to learning rate, and regularization refers to lambda hyperparameter controlling the effect of regularization terms\n",
    "mf = MatrixFactorizationSGD(n_factors=10, n_epochs=10, learning_rate=0.001, regularization=0.001)\n",
    "mf.fit(train_data, verbose=True)\n",
    "\n",
    "# Get top-10 recommendations for user 1\n",
    "recommendations = mf.recommend_topk(user_id=1, train_data=train_data, n=10)\n",
    "print(\"Top-10 Recommendations for user 1:\")\n",
    "for item, score in recommendations:\n",
    "    print(f\"Item {item}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca8f13da-23b2-43ca-97e4-9f7af8268311",
   "metadata": {},
   "source": [
    "# 4) Evaluation of user-based, item-based, and MF models for rating prediction task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f07e8bc-b852-4949-9de0-95ef1e8a33f6",
   "metadata": {},
   "source": [
    "### Question 13: What is the performance of user-based CF in terms of RMSE for k=50?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df5e4cc-a178-4292-95d8-18af5271215e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_user_cf_rating_prediction(train_data: pd.DataFrame, test_data: pd.DataFrame, user_similarity_matrix: pd.DataFrame, k=5) -> float:\n",
    "    \"\"\"\n",
    "    Evaluate user-based CF using RMSE on a test set.\n",
    "    \n",
    "    Parameters:\n",
    "    - train_data: pd.DataFrame with ['user_id', 'item_id', 'rating'] used for training\n",
    "    - test_data: pd.DataFrame with ['user_id', 'item_id', 'rating'] used for testing\n",
    "    - user_similarity_matrix: user-user similarity matrix (computed from train set)\n",
    "    - k: number of neighbors\n",
    "    \n",
    "    Returns:\n",
    "    - float: RMSE value\n",
    "    \"\"\"\n",
    "    result = 0.0\n",
    "\n",
    "    ############# Your code here ############\n",
    "    \n",
    "    #########################################\n",
    "\n",
    "    return result\n",
    "\n",
    "k = 50\n",
    "start_time = time.time()\n",
    "print(f\"RMSE of user-based CF for k={k} is {evaluate_user_cf_rating_prediction(train_data, test_data, user_similarity_matrix, k):.4f}\")\n",
    "end_time = time.time()\n",
    "print(f'Running time: {end_time - start_time:.4f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e8fe066-71d1-41ca-9fb9-548d6f190252",
   "metadata": {},
   "source": [
    "### Question 14: Can you further improve the performance of user-based CF? Tune user-based CF with k={10, 30, 50, 70, 100} and visualize the performance with k values in x-axis and corresponding RMSE values in y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd63574-be1a-4a5d-9efd-8ad812d739f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = [10,30,50,70,100]\n",
    "user_based_RMSEs = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "############# Your code here ############\n",
    "    \n",
    "#########################################\n",
    "\n",
    "end_time = time.time()\n",
    "print(f'Running time: {end_time - start_time:.4f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "029849df-67eb-41ca-a16c-4c6d99176cdd",
   "metadata": {},
   "source": [
    "Discuss your observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e89c1cfa-e3d8-4769-8c9f-3704887ae560",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "edfbae5d-ba95-420c-a8af-875cfd708a7f",
   "metadata": {},
   "source": [
    "### Question 15: What is the performance of item-based CF in terms of RMSE for k=50?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14754082-92f1-481f-9fc0-a95ad79210e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_item_cf_rating_prediction(train_data: pd.DataFrame, test_data: pd.DataFrame, item_similarity_matrix: pd.DataFrame, k=5) -> float:\n",
    "    \"\"\"\n",
    "    Evaluate item-based CF using RMSE on a test set.\n",
    "    \n",
    "    Parameters:\n",
    "    - train_data: pd.DataFrame with ['user_id', 'item_id', 'rating'] used for training\n",
    "    - test_data: pd.DataFrame with ['user_id', 'item_id', 'rating'] used for testing\n",
    "    - item_similarity_matrix: item-item similarity matrix (computed from train set)\n",
    "    - k: number of neighbors\n",
    "    \n",
    "    Returns:\n",
    "    - float: RMSE value\n",
    "    \"\"\"\n",
    "    result = 0.0\n",
    "\n",
    "    ############# Your code here ############\n",
    "    \n",
    "    #########################################\n",
    "\n",
    "    return result\n",
    "\n",
    "k = 50\n",
    "start_time = time.time()\n",
    "print(f\"RMSE of user-based CF for k={k} is {evaluate_item_cf_rating_prediction(train_data, test_data, item_similarity_matrix, k):.4f}\")\n",
    "end_time = time.time()\n",
    "print(f'Running time: {end_time - start_time:.4f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fae41c-1f97-44d4-a97b-13bc9e0fb609",
   "metadata": {},
   "source": [
    "### Question 16: Can you further improve the performance of item-based CF? Tune item-based CF with k={10, 30, 50, 70, 100} and visualize the performance with k values in x-axis and corresponding RMSE values in y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b249510a-b64c-4566-92a5-fbba9e3083df",
   "metadata": {},
   "outputs": [],
   "source": [
    "K = [10,30,50,70,100]\n",
    "item_based_RMSEs = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "############# Your code here ############\n",
    "    \n",
    "#########################################\n",
    "\n",
    "end_time = time.time()\n",
    "print(f'Running time: {end_time - start_time:.4f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "413af114-3e5a-4c6d-a131-19aacb3c5eac",
   "metadata": {},
   "source": [
    "Discuss your observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cee152-f05f-486d-a0ba-50111c8ad5cc",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b4f0e2d3-f4c8-491a-acec-1e7f63b12cf9",
   "metadata": {},
   "source": [
    "### Question 17: What is the performance of MF model in terms of RMSE for the following hyperparameter values?\n",
    "\n",
    "    n_factors=50\n",
    "\n",
    "    n_epochs=30\n",
    "\n",
    "    learning_rate=0.001\n",
    "\n",
    "    regularization=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb82f516-b5cd-483f-93a8-15c127b009f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_mf_rating_prediction(train_data: pd.DataFrame, test_data: pd.DataFrame, n_factors: float, n_epochs: float, learning_rate: float) -> float:\n",
    "    \"\"\"\n",
    "    Evaluate MF using RMSE on a test set.\n",
    "    \n",
    "    Parameters:\n",
    "    - train_data: pd.DataFrame with ['user_id', 'item_id', 'rating'] used for training\n",
    "    - test_data: pd.DataFrame with ['user_id', 'item_id', 'rating'] used for testing\n",
    "    - n_factors: embedding size\n",
    "    - n_epochs: number of training epochs\n",
    "    - learning_rate: Learning rate\n",
    "    \n",
    "    Returns:\n",
    "    - float: RMSE value\n",
    "    \"\"\"\n",
    "    # Hint: set the regularization hyperparameter to 0.001\n",
    "\n",
    "    result = 0.0\n",
    "\n",
    "    ############# Your code here ############\n",
    "    \n",
    "    #########################################\n",
    "    \n",
    "    return result\n",
    "\n",
    "n_factors, n_epochs, learning_rate = 50, 30, 0.001\n",
    "start_time = time.time()\n",
    "print(f\"RMSE of MF for n_factors={n_factors}, n_epochs={n_epochs}, learning_rate={learning_rate} is {evaluate_mf_rating_prediction(train_data, test_data, n_factors, n_epochs, learning_rate):.4f}\")\n",
    "end_time = time.time()\n",
    "print(f'Running time: {end_time - start_time:.4f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d16a1bf-2525-4c79-aa2e-3a52c8c26553",
   "metadata": {},
   "source": [
    "### Question 18: Tune MF model with n_factors={10, 30, 50, 70, 90} and the rest of hyperparameters as n_epochs=30, learning_rate=0.001. Visualize the performance with n_factors in x-axis and corresponding RMSE values in y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1109397f-812b-4480-929b-49e26d8e0d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_factors = [10,30,50,70,90]\n",
    "n_epochs, learning_rate = 30, 0.001\n",
    "mf_RMSEs = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "############# Your code here ############\n",
    "    \n",
    "#########################################\n",
    "\n",
    "end_time = time.time()\n",
    "print(f'Running time: {end_time - start_time:.4f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb836f7-4104-4ea8-8633-e5b241f6a3ef",
   "metadata": {},
   "source": [
    "Discuss your observation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e98560f-0acd-4d1c-bde0-d81114dca728",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7562062e-d6e0-45f4-beaf-c54df63fd8fd",
   "metadata": {},
   "source": [
    "### Question 19: Tune MF model with n_epochs={10, 30, 50, 70, 90} and the rest of hyperparameters as n_factors=10, learning_rate=0.001. Visualize the performance with n_factors in x-axis and corresponding RMSE values in y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17fda8b-77cb-4629-b838-bd8af6a93a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = [10,30,50,70,90]\n",
    "n_factors, learning_rate = 10, 0.001\n",
    "mf_RMSEs = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "############# Your code here ############\n",
    "    \n",
    "#########################################\n",
    "\n",
    "end_time = time.time()\n",
    "print(f'Running time: {end_time - start_time:.4f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa30929-80b2-42a9-b435-1bca77784530",
   "metadata": {},
   "source": [
    "Discuss your observation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f05014d8-339c-4498-887c-e6739b9b6940",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "68224773-c3b4-490b-ae3f-d1f3452c6d8b",
   "metadata": {},
   "source": [
    "### Question 20: Tune MF model with learning_rate={0.001, 0.005, 0.01, 0.05} and the rest of hyperparameters as n_factors=10, n_epochs=90. Visualize the performance with n_factors in x-axis and corresponding RMSE values in y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acd6a30a-1be7-4cbb-9de9-4a1baf51410e",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = [0.001,0.005,0.01,0.05]\n",
    "n_factors, n_epochs = 10, 90\n",
    "mf_RMSEs = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "############# Your code here ############\n",
    "    \n",
    "#########################################\n",
    "\n",
    "end_time = time.time()\n",
    "print(f'Running time: {end_time - start_time:.4f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1709aa9c-1e35-4854-b01d-a1e82c81e60f",
   "metadata": {},
   "source": [
    "Discuss your observation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74736c7e-72ae-4204-941d-9c856de2c7d9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3df0f30-70c8-4c81-b025-4e63413a5b42",
   "metadata": {},
   "source": [
    "# 6) Evaluation of user-based, item-based, and MF models for ranking task"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642da962-2b8f-4c9f-858f-24a235788e1f",
   "metadata": {},
   "source": [
    "### Question 21: What is the performance of user-based CF in terms of nDCG for k=30?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7197d794-baba-4c3e-b8bd-09ae301e4ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_user_cf_ranking(train_data, test_data, user_similarity_matrix, k=5):\n",
    "    \"\"\"\n",
    "    Evaluate User-based CF ranking performance using NDCG@K.\n",
    "    \n",
    "    Args:\n",
    "        train_data (pd.DataFrame): training ratings [user_id, item_id, rating]\n",
    "        test_data (pd.DataFrame): test ratings [user_id, item_id, rating]\n",
    "        user_similarity_matrix (pd.DataFrame): precomputed user-user similarity matrix\n",
    "        k (int): number of neighbors for prediction\n",
    "    \n",
    "    Returns:\n",
    "        float: average NDCG@K across test users\n",
    "    \"\"\"\n",
    "    result = 0.0\n",
    "\n",
    "    ############# Your code here ############\n",
    "    \n",
    "    #########################################\n",
    "    \n",
    "    return result\n",
    "\n",
    "k = 30\n",
    "start_time = time.time()\n",
    "print(f\"NDCG of user-based CF for k={k} is {evaluate_user_cf_ranking(train_data, test_data, user_similarity_matrix, k):.4f}\")\n",
    "end_time = time.time()\n",
    "print(f'Running time: {end_time - start_time:.4f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5d5d2e-1393-4e90-b564-88cedc5e2c55",
   "metadata": {},
   "source": [
    "### Question 22: What is the performance of item-based CF in terms of nDCG for k=30?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a1f5ad6-f641-4c85-9cbc-68d6e72b57d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_item_cf_ranking(train_data, test_data, item_similarity_matrix, k=5):\n",
    "    \"\"\"\n",
    "    Evaluate Item-based CF ranking performance using NDCG@K.\n",
    "    \n",
    "    Args:\n",
    "        train_data (pd.DataFrame): training ratings [user_id, item_id, rating]\n",
    "        test_data (pd.DataFrame): test ratings [user_id, item_id, rating]\n",
    "        item_similarity_matrix (pd.DataFrame): precomputed item-item similarity matrix\n",
    "        k (int): number of neighbors for prediction\n",
    "    \n",
    "    Returns:\n",
    "        float: average NDCG@K across test users\n",
    "    \"\"\"\n",
    "    result = 0.0\n",
    "\n",
    "    ############# Your code here ############\n",
    "    \n",
    "    #########################################\n",
    "    \n",
    "    return result\n",
    "\n",
    "k = 30\n",
    "start_time = time.time()\n",
    "print(f\"NDCG of item-based CF for k={k} is {evaluate_item_cf_ranking(train_data, test_data, item_similarity_matrix, k):.4f}\")\n",
    "end_time = time.time()\n",
    "print(f'Running time: {end_time - start_time:.4f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b0ddef6-e1be-4c6d-af7d-b4cd6968ed37",
   "metadata": {},
   "source": [
    "### Question 23: What is the performance of MF model in terms of NDCG for the following hyperparameter values?\n",
    "\n",
    "    n_factors=50\n",
    "\n",
    "    n_epochs=30\n",
    "\n",
    "    learning_rate=0.001\n",
    "\n",
    "    regularization=0.001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "becf5a95-78bd-4686-8699-7b454e553ec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_mf_ranking(train_data: pd.DataFrame, test_data: pd.DataFrame, n_factors: float, n_epochs: float, learning_rate: float) -> float:\n",
    "    \"\"\"\n",
    "    Evaluate MF in terms of NDCG.\n",
    "    \n",
    "    Parameters:\n",
    "    - train_data: pd.DataFrame with ['user_id', 'item_id', 'rating'] used for training\n",
    "    - test_data: pd.DataFrame with ['user_id', 'item_id', 'rating'] used for testing\n",
    "    - n_factors: embedding size\n",
    "    - n_epochs: number of training epochs\n",
    "    - learning_rate: Learning rate\n",
    "    \n",
    "    Returns:\n",
    "    - float: NDCG value\n",
    "    \"\"\"\n",
    "    # Hint: set the regularization hyperparameter to 0.001\n",
    "\n",
    "    result = 0.0\n",
    "\n",
    "    ############# Your code here ############\n",
    "    \n",
    "    #########################################\n",
    "    \n",
    "    return result\n",
    "\n",
    "n_factors, n_epochs, learning_rate = 50, 30, 0.001\n",
    "start_time = time.time()\n",
    "print(f\"NDCG of MF for n_factors={n_factors}, n_epochs={n_epochs}, learning_rate={learning_rate} is {evaluate_mf_ranking(train_data, test_data, n_factors, n_epochs, learning_rate):.4f}\")\n",
    "end_time = time.time()\n",
    "print(f'Running time: {end_time - start_time:.4f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd01fb5-4f53-4621-a8bb-b47785a157ea",
   "metadata": {},
   "source": [
    "### Question 24: Tune MF model with n_factors={10, 30, 50, 70, 90} and the rest of hyperparameters as n_epochs=30, learning_rate=0.001. Visualize the performance with n_factors in x-axis and corresponding NDCG values in y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2831fd1f-88c3-4fea-8978-05974b74647d",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_factors = [10,30,50,70,90]\n",
    "n_epochs, learning_rate = 30, 0.001\n",
    "mf_NDCGs = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "############# Your code here ############\n",
    "    \n",
    "#########################################\n",
    "\n",
    "end_time = time.time()\n",
    "print(f'Running time: {end_time - start_time:.4f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e57cc8-9020-48ad-aa6e-642c3a894f5c",
   "metadata": {},
   "source": [
    "### Question 25: Tune MF model with n_epochs={10, 30, 50, 70, 90} and the rest of hyperparameters as n_factors=30, learning_rate=0.001. Visualize the performance with n_factors in x-axis and corresponding NDCG values in y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93fef30f-d91d-46ad-b258-1fe819f61df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = [10,30,50,70,90]\n",
    "n_factors, learning_rate = 30, 0.001\n",
    "mf_NDCGs = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "############# Your code here ############\n",
    "    \n",
    "#########################################\n",
    "\n",
    "end_time = time.time()\n",
    "print(f'Running time: {end_time - start_time:.4f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76fbfea0-85bd-47ce-ac62-e3bfaa6d3177",
   "metadata": {},
   "source": [
    "### Question 26: Tune MF model with learning_rate={0.001, 0.005, 0.01, 0.05} and the rest of hyperparameters as n_factors=10, n_epochs=90. Visualize the performance with n_factors in x-axis and corresponding NDCG values in y-axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cf5226-c175-4d47-98a8-704550915fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = [0.001,0.005,0.01,0.05]\n",
    "n_factors, n_epochs = 10, 90\n",
    "mf_NDCGs = []\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "############# Your code here ############\n",
    "    \n",
    "#########################################\n",
    "\n",
    "end_time = time.time()\n",
    "print(f'Running time: {end_time - start_time:.4f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3e7660-ce0a-4b56-b679-bcf4de71bc61",
   "metadata": {},
   "source": [
    "# 7) Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "154e232b-1ad8-47f2-a3e5-c742fc4c73ae",
   "metadata": {},
   "source": [
    "### Question 27: Compare the performance of CF methods with the content-based recommendation model developed in assignment 1. Discuss your observations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43adaff-e8c5-445f-98cf-638d897bc6c4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25ce9dfe-8b85-4a33-ab23-70e3273ac610",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
